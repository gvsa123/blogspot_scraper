{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "\n",
    "documents = [\n",
    "    \"Human machine social interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human social system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "    \"Pocahontas is a social human who likes interaction\",\n",
    "    \"There was a shooting in alabama\"\n",
    "]\n",
    "\n",
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]\n",
    "\n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    #print(f\"ON {text}...\")\n",
    "    for token in text:\n",
    "        #print(token)\n",
    "        frequency[token] += 1 # frequency count\n",
    "\n",
    "# list of unique words per document in corpus\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "# returns gensim object of dictionary mapping\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# list of tuple(token_id, token_count)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['human', 'social', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'social', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey'],\n",
       " ['social', 'human'],\n",
       " []]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "[text for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n['computer', 'human', 'interface', 'social', 'response', 'survey', 'system', 'time', 'user', 'eps', 'trees', 'graph', 'minors']\n"
     ]
    }
   ],
   "source": [
    "# also dictionary.token2id()\n",
    "print(dictionary.keys())\n",
    "print([dictionary[i] for i in dictionary.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1)],\n",
       " [(0, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(2, 1), (6, 1), (8, 1), (9, 1)],\n",
       " [(1, 1), (3, 1), (6, 2), (9, 1)],\n",
       " [(4, 1), (7, 1), (8, 1)],\n",
       " [(10, 1)],\n",
       " [(10, 1), (11, 1)],\n",
       " [(10, 1), (11, 1), (12, 1)],\n",
       " [(5, 1), (11, 1), (12, 1)],\n",
       " [(1, 1), (3, 1)],\n",
       " []]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# (token_id, token_count)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Contents of dictionary: ['computer', 'human', 'interface', 'social', 'response', 'survey', 'system', 'time', 'user', 'eps', 'trees', 'graph', 'minors']\n"
     ]
    }
   ],
   "source": [
    "# Contents of dictionary\n",
    "print(f\"Contents of dictionary: {[dictionary[i] for i in dictionary.keys()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSI model using dictionary as training data\n",
    "from gensim import models\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.624*\"system\" + 0.324*\"user\" + 0.323*\"social\" + 0.323*\"human\" + 0.300*\"eps\" + 0.233*\"computer\" + 0.209*\"interface\" + 0.204*\"response\" + 0.204*\"time\" + 0.161*\"survey\"')]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Output most meaningful words in corpus\n",
    "lsi.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_doc = \"Girard is a social science student interested in computer science and human computer interaction and natural language processing\"\n",
    "#test_doc = \"Girard is a mechanic and a mountaineer that likes to cook.\"\n",
    "\n",
    "# Add last sentence to bring similarity score up\n",
    "test_doc = \"We started off early, but by the time we got a glimpse of the Aberdeen glacier, there were two parties midway through the ice pitch already. We could barely make them out from a far, and it seemed like the wall was not that much of a deal. It was pretty daunting once you get close enought to appreciate the massive ice formation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 0.20380793062023445)]\n"
     ]
    }
   ],
   "source": [
    "vec_bow = dictionary.doc2bow(test_doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]  # convert the query test_doc to LSI matrix and calculate cosine similarity against the lsi model\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])"
   ]
  },
  {
   "source": [
    "index.get_similarities(test_doc, vec_lsi)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "index.save('/tmp/deerwester.index')\n",
    "index = similarities.MatrixSimilarity.load('/tmp/deerwester.index')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Human machine social interface for lab abc computer applications',\n",
       " 'A survey of user opinion of computer system response time',\n",
       " 'The EPS user interface management system',\n",
       " 'System and human social system engineering testing of EPS',\n",
       " 'Relation of user perceived response time to error measurement',\n",
       " 'The generation of random binary unordered trees',\n",
       " 'The intersection graph of paths in trees',\n",
       " 'Graph minors IV Widths of trees and well quasi ordering',\n",
       " 'Graph minors A survey',\n",
       " 'Pocahontas is a social human who likes interaction',\n",
       " 'There was a shooting in alabama']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 1.0), (1, 1.0), (2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (7, 1.0), (8, 1.0), (9, 1.0), (10, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi]  # perform a similarity query against the corpus\n",
    "print(list(enumerate(sims)))  # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0 Human machine social interface for lab abc computer applications\n1.0 A survey of user opinion of computer system response time\n1.0 The EPS user interface management system\n1.0 System and human social system engineering testing of EPS\n1.0 Relation of user perceived response time to error measurement\n1.0 The generation of random binary unordered trees\n1.0 The intersection graph of paths in trees\n1.0 Graph minors IV Widths of trees and well quasi ordering\n1.0 Graph minors A survey\n1.0 Pocahontas is a social human who likes interaction\n0.0 There was a shooting in alabama\n"
     ]
    }
   ],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "for doc_position, doc_score in sims:\n",
    "    print(doc_score, documents[doc_position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0, 1.0),\n",
       " (1, 1.0),\n",
       " (2, 1.0),\n",
       " (3, 1.0),\n",
       " (4, 1.0),\n",
       " (5, 1.0),\n",
       " (6, 1.0),\n",
       " (7, 1.0),\n",
       " (8, 1.0),\n",
       " (9, 1.0),\n",
       " (10, 0.0)]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "type(documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}